{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP 10-12-2019",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharat-shankar/NLP_J045/blob/master/Homework/Spacy_Lem_Tok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOSkxtGD69YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#Reading Data\n",
        "data = pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\",lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCxu4ArJvOZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WzcuBgFvUrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spacy_lem_tok_pos(str):\n",
        "  res = dict()\n",
        "  noun = []\n",
        "  wt = []\n",
        "  pos = []\n",
        "  lem = []\n",
        "  dep = []\n",
        "  sentence = sp(str)\n",
        "  \n",
        "  for word in sentence:\n",
        "    wt.append(word.text)\n",
        "    pos.append(word.pos_)\n",
        "    lem.append(word.lemma_)\n",
        "    dep.append(word.dep_)\n",
        "\n",
        "  for nouns in sentence.noun_chunks:\n",
        "    noun.append(nouns)\n",
        "\n",
        "  res[\"Word Tokenizer\"] = wt\n",
        "  res[\"Lemmatizer\"] = lem\n",
        "  res[\"Pos Tagger\"] = pos\n",
        "  res[\"Dependency Parser\"] = dep\n",
        "  res[\"Nouns\"] = noun\n",
        "\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SwvWwW1j0bwl",
        "colab": {}
      },
      "source": [
        "data[\"reviewTextSpacy\"] = data.reviewText.apply(spacy_lem_tok_pos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v9Pcci_0QBq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "0a8f4026-9da8-4464-de75-9ea28b1ec1bf"
      },
      "source": [
        "data.reviewTextSpacy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        {'Word Tokenizer': ['I', 'bought', 'my', 'firs...\n",
              "1        {'Word Tokenizer': ['WHY', 'THIS', 'BELATED', ...\n",
              "2        {'Word Tokenizer': ['I', 'have', 'an', 'HP', '...\n",
              "3        {'Word Tokenizer': ['I', ''ve', 'started', 'do...\n",
              "4        {'Word Tokenizer': ['For', 'simple', 'calculat...\n",
              "                               ...                        \n",
              "53253    {'Word Tokenizer': ['What', 'I', 'like', 'abou...\n",
              "53254    {'Word Tokenizer': ['This', 'Accuteck', 'ShipP...\n",
              "53255    {'Word Tokenizer': ['I', 'ship', 'a', 'lot', '...\n",
              "53256    {'Word Tokenizer': ['This', 'is', 'a', 'great'...\n",
              "53257    {'Word Tokenizer': ['When', 'asked', 'to', 're...\n",
              "Name: reviewTextSpacy, Length: 53258, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sakUn5Dg0gSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"summarySpacy\"] = data.summary.apply(spacy_lem_tok_pos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmW6-ABJ0lJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4cfd1371-1ccd-4bc1-c065-36b77a6a243a"
      },
      "source": [
        "data.summarySpacy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        {'Word Tokenizer': ['A', 'solid', 'performer',...\n",
              "1        {'Word Tokenizer': ['Price', 'of', 'GOLD', 'is...\n",
              "2        {'Word Tokenizer': ['Good', 'functionality', '...\n",
              "3        {'Word Tokenizer': ['One', 'of', 'the', 'last'...\n",
              "4        {'Word Tokenizer': ['Still', 'the', 'best'], '...\n",
              "                               ...                        \n",
              "53253    {'Word Tokenizer': ['Portable', 'and', 'very',...\n",
              "53254    {'Word Tokenizer': ['Accuteck', 'ShipPro', 'Di...\n",
              "53255    {'Word Tokenizer': ['Extremely', 'accurate', '...\n",
              "53256    {'Word Tokenizer': ['Fast', ',', 'Easy', 'and'...\n",
              "53257    {'Word Tokenizer': ['Great', 'Value', 'on', 'a...\n",
              "Name: summarySpacy, Length: 53258, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}